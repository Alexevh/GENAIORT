{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZiKJBKNKGcU8",
        "4NsMrvxdBG6A",
        "cBcLoRnsGV8E",
        "FG8oQP8uJZZ7",
        "io8zD2FtJWpq",
        "C0i0ZQEWPSaD",
        "MN2CcL3fDCc_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratorio sobre Agents y Tools"
      ],
      "metadata": {
        "id": "X1kGcqxh1Z6s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f1d0520"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "En este laboratorio práctico sobre Agentes y Tools explorarás cómo construir agentes inteligentes utilizando la librería LangChain y LangGraph.\n",
        "\n",
        "A través de una serie de ejercicios prácticos, aprenderás a:\n",
        "\n",
        "- Crear tu primer Agente ReAct.\n",
        "- Integrar múltiples tools en un agente.\n",
        "- Construir un chatbot con LangGraph.\n",
        "- Agregar herramientas externas como Wikipedia y APIs de clima.\n",
        "- Incorporar una base de conocimiento utilizando un índice de Pinecone.\n",
        "- Implementar condiciones personalizadas para la selección de tools.\n",
        "\n",
        "Este laboratorio está diseñado para ser un espacio de práctica donde podrás experimentar y aplicar los conceptos de agentes y tools en un entorno interactivo."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U \\\n",
        "  langchain==0.3.7 \\\n",
        "  langchain-core==0.3.18 \\\n",
        "  langchain-openai==0.2.3 \\\n",
        "  langchain-community==0.3.7 \\\n",
        "  langchain-pinecone==0.2.0 \\\n",
        "  langchain-huggingface==0.1.2 \\\n",
        "  langgraph==0.2.19 \\\n",
        "  sentence-transformers \\\n",
        "  pinecone-client \\\n",
        "  pydantic==2.9.2 \\\n",
        "  pypdf"
      ],
      "metadata": {
        "id": "DCVKnlNo-A3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 1: Creando tu primer ReAct Agent\n",
        "Crea un agente ReAct que use un modelo de lenguaje (ChatOpenAI) y una tool para contar cuántas letras “r” hay en una palabra.\n",
        "El agente debe recibir una pregunta del usuario, invocar la herramienta y responder con el resultado."
      ],
      "metadata": {
        "id": "ZiKJBKNKGcU8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-nG0wDi1YNW"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from google.colab import userdata\n",
        "\n",
        "# TODO: Inicializar el modelo de lenguaje gpt-4o-mini usando ChatOpenAI\n",
        "model = ChatOpenAI(api_key=userdata.get('__________'), model=\"__________\")\n",
        "\n",
        "# TODO: Define una tool que cuente las 'r' en una palabra\n",
        "@tool\n",
        "def count_r_in_word(word: str) -> int:\n",
        "    \"\"\"Count how many 'r' letters are in the given word.\"\"\"\n",
        "    return __________\n",
        "\n",
        "# TODO: Crear el agente con create_react_agent\n",
        "app = create_react_agent(model=model, tools=[__________])\n",
        "\n",
        "# Pregunta del usuario\n",
        "query = \"How many r's are in the word 'Terrarium'?\"\n",
        "\n",
        "# TODO: Invocar el agente y mostrar la respuesta final\n",
        "response = __________\n",
        "print(response['messages'][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 2: Agregando múltiples tools\n",
        "Amplía el agente para incluir una segunda herramienta que calcule el área de un rectángulo.\n",
        "Luego, haz una consulta que combine ambas herramientas en una sola interacción."
      ],
      "metadata": {
        "id": "4NsMrvxdBG6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Define una tool que calcule el área de un rectángulo\n",
        "@tool\n",
        "def calculate_rectangle_area(length: float, width: float) -> float:\n",
        "    \"\"\"Calculate the area of a rectangle given its length and width.\"\"\"\n",
        "    return __________\n",
        "\n",
        "# TODO: Crear el agente con ambas tools\n",
        "app = create_react_agent(model=model, tools=[__________, __________])\n",
        "\n",
        "query = \"What is the area of a rectangle with length 5 and width 11? and how many r's are in 'Race'?\"\n",
        "\n",
        "# TODO: Invocar y mostrar la respuesta\n",
        "response = __________\n",
        "print(response['messages'][-1].content)"
      ],
      "metadata": {
        "id": "SG9Jne9oEvNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 3: Construyendo un chatbot con LangGraph\n",
        "Crea un StateGraph básico con un solo nodo chatbot que responda preguntas directamente usando el modelo LLM."
      ],
      "metadata": {
        "id": "cBcLoRnsGV8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END, MessagesState\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# TODO: Inicializa el modelo LLM\n",
        "llm = ChatOpenAI(api_key=userdata.get('__________'), model=\"__________\")\n",
        "\n",
        "# TODO: Crea el grafo y define el nodo chatbot\n",
        "graph_builder = __________\n",
        "\n",
        "def chatbot(state: MessagesState):\n",
        "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
        "\n",
        "# TODO: Agrega nodos y bordes al grafo\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# TODO: Invoca el grafo con una consulta\n",
        "response = graph.invoke({\"messages\": [(\"human\", \"Who is Ada Lovelace?\")]})\n",
        "print(response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "98w8jdehGpZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 4: Agregando WikipediaTool y usando stream_tool_responses\n",
        "Integra la tool de Wikipedia al chatbot y usa la función stream_tool_responses para observar cómo el agente decide cuándo invocar la herramienta y cómo se entregan las respuestas en streaming."
      ],
      "metadata": {
        "id": "FG8oQP8uJZZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install wikipedia"
      ],
      "metadata": {
        "id": "OC2V5ryDK2IH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langgraph.graph import MessagesState\n",
        "\n",
        "# TODO: Inicializa el wrapper de Wikipedia\n",
        "api_wrapper = __________\n",
        "wikipedia_tool = __________\n",
        "\n",
        "tools = [wikipedia_tool]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "def chatbot(state: MessagesState):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder = StateGraph(MessagesState)\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# TODO: Crea el nodo de herramientas y define las transiciones\n",
        "tool_node = ToolNode(tools=tools)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "def stream_tool_responses(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
        "        for item in event.values():\n",
        "            print(\"Agent:\", item[\"messages\"])\n",
        "\n",
        "query = \"Who is Alan Turing?\"\n",
        "stream_tool_responses(query)"
      ],
      "metadata": {
        "id": "WCLCEbcnIxKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 5: Agregando una Tool de API externa\n",
        "Agrega una tool que obtenga el clima actual de una ciudad usando la API de Open-Meteo.\n",
        "\n",
        "Importante: en esta parte se puede utilizar cualquier otra API externa, la mencionada anteriormente es una sugerencia."
      ],
      "metadata": {
        "id": "io8zD2FtJWpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# TODO: Completar la función para obtener el clima actual\n",
        "@tool\n",
        "def weather_tool(city: str) -> str:\n",
        "    \"\"\"\n",
        "    Retrieve current weather for a city using Open-Meteo.\n",
        "    \"\"\"\n",
        "    # TODO: completar los pasos de geocodificación y consulta del clima\n",
        "    geo_url = f\"https://geocoding-api.open-meteo.com/v1/search?name={city}\"\n",
        "    geo_resp = __________\n",
        "    # ...\n",
        "\n",
        "# TODO: Agrega la nueva tool al grafo\n",
        "tools = [wikipedia_tool, weather_tool]\n",
        "\n",
        "# TODO: Volver a crear y compilar el grafo"
      ],
      "metadata": {
        "id": "mnc4bBSQJYiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 6: Agregando una base de conocimiento\n",
        "Agrega una tool que consulte un índice de Pinecone con embeddings de un documento PDF."
      ],
      "metadata": {
        "id": "C0i0ZQEWPSaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# TODO: Inicializar Pinecone y embeddings\n",
        "os.environ[\"PINECONE_API_KEY\"] = userdata.get(\"pinecone_api_key\")\n",
        "pc = Pinecone(api_key=userdata.get(\"pinecone_api_key\"))\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Crear índice y vector store\n",
        "index_name = \"docs-index\"\n",
        "pc.create_index(name=index_name, dimension=384, metric=\"cosine\",\n",
        "                spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"))\n",
        "\n",
        "vector_store = PineconeVectorStore.from_documents(chunks, embeddings, index_name=index_name)\n",
        "\n",
        "@tool\n",
        "def db_knowledge(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Retrieve relevant knowledge from the Pinecone vector store (LTM).\n",
        "    \"\"\"\n",
        "    retriever = __________\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "    if not docs:\n",
        "        return \"No relevant knowledge found.\"\n",
        "    return \"\\n\".join([r.page_content for r in docs])\n",
        "\n",
        "# TODO: Agregar tool, volver a construir el grafo y compilarlo"
      ],
      "metadata": {
        "id": "clN4jLC_LfAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parte 7: Condiciones personalizadas para decisión de uso de tools\n",
        "Crea un agente que decida entre las diferentes tools según el contenido del mensaje del usuario.\n",
        "- Si el mensaje menciona \"clima\" → invocar weather_tool.\n",
        "- Si menciona \"wiki\" → invocar wikipedia_tool.\n",
        "- Si menciona \"documento\" → invocar db_knowledge.\n",
        "- Para cualquier otro mensaje → invocar al LLM y terminar el flujo sin llamar a ninguna tool.\n",
        "\n",
        "*Tener en cuenta que cada tool debe ser creada en un nodo independiente."
      ],
      "metadata": {
        "id": "MN2CcL3fDCc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END, MessagesState\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "# TODO: Crear nodos para el chatbot y las diferentes tools\n",
        "\n",
        "\n",
        "# TODO: Definir condición personalizada para elegir tool\n",
        "def tool_selector(state: MessagesState):\n",
        "    last_message = state[\"messages\"][-1]\n",
        "    if not isinstance(last_message, HumanMessage):\n",
        "        return END\n",
        "\n",
        "    content = last_message.content.lower()\n",
        "\n",
        "    return \"tool_node_name\"\n",
        "\n",
        "graph_builder.add_conditional_edges(START, tool_selector, [])\n",
        "\n",
        "# TODO: Agregar aristas faltantes necesarias\n",
        "\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "0GdfTfFeDtWX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}