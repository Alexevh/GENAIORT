{"cells":[{"cell_type":"markdown","metadata":{"id":"VBCSNaCdrBz-"},"source":["# Laboratorio: Setup y uso b√°sico de LLMs con LangChain + Prompt engineering avanzado\n","\n","Este laboratorio est√° pensado para completarse en ~2 horas. Trabajaremos en Google Colab con recursos gratuitos, usando la Inference API de Hugging Face y un modelo instruct abierto.\n","\n","- Contenidos:\n","  - Setup en Colab y configuraci√≥n de Hugging Face Inference API\n","  - Uso b√°sico de LLMs con LangChain (LCEL)\n","  - Par√°metros de decodificaci√≥n y control de estilo\n","  - Prompt engineering avanzado: zero-shot, few-shot, Chain of Thought, Role Prompting y salida estructurada (JSON)\n","\n","Al finalizar, podr√°s:\n","- Conectarte a un LLM instruct v√≠a Hugging Face Inference API desde LangChain.\n","- Construir cadenas simples con `prompt | llm | parser`.\n","- Dise√±ar prompts efectivos y controlar formato de salida (incluido JSON).\n"]},{"cell_type":"markdown","metadata":{"id":"4RTG7_ybrBz_"},"source":["## Parte 0 ‚Äî Setup (Colab + librer√≠as + token)\n","\n","Usaremos versiones estables para minimizar fricci√≥n en Colab. Asegurate de ejecutar esta secci√≥n antes de continuar.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxoJSkLcrBz_","outputId":"36ff7967-4de2-4f8e-ab65-bbd925fa6295"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.4/1.0 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.4/1.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/443.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m443.5/443.5 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m373.2/373.2 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# Instalar dependencias principales (versiones estables)\n","!pip -q install -U \\\n","  \"langchain==0.3.27\" \\\n","  \"langchain-community==0.3.27\" \\\n","  \"langchain-huggingface==0.3.1\" \\\n","  \"transformers==4.55.2\" \\\n","  \"huggingface_hub==0.34.4\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmVbT5uRxn5R","outputId":"4bf9c413-6e72-433b-9d10-fd1cb0910438"},"outputs":[{"name":"stdout","output_type":"stream","text":["langchain => 0.3.27\n","langchain-community => 0.3.27\n","langchain-huggingface => 0.3.1\n","transformers => 4.55.2\n","huggingface_hub => 0.34.4\n"]}],"source":["from importlib.metadata import version, PackageNotFoundError\n","\n","for dist in [\"langchain\", \"langchain-community\", \"langchain-huggingface\",\n","             \"transformers\", \"huggingface_hub\"]:\n","    try:\n","        print(dist, \"=>\", version(dist))\n","    except PackageNotFoundError:\n","        print(dist, \"no instalado\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M9EJxPOCrB0A","outputId":"3f389cf0-dc68-4fc4-8fb2-9c56ef6a4a5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n","PyTorch: 2.6.0+cu124\n","CUDA disponible: True\n"]}],"source":["# Comprobar versi√≥n de Python y GPU/CPU\n","import sys, subprocess, torch\n","print(sys.version)\n","try:\n","    import torch\n","    print(\"PyTorch:\", torch.__version__)\n","    print(\"CUDA disponible:\", torch.cuda.is_available())\n","except Exception as e:\n","    print(\"PyTorch no disponible o sin CUDA\", e)\n"]},{"cell_type":"markdown","metadata":{"id":"2Ug4tn-VrB0A"},"source":["### Configuraci√≥n del token de Hugging Face\n","\n","Para usar la Hugging Face Inference API, necesit√°s un token personal (gratuito). En Colab se recomienda guardarlo en `userdata`:\n","\n","1. Crear el token en `https://huggingface.co/settings/tokens`.\n","2. En Colab: Abre el men√∫ en la barra izquierda haciendo click en la llave ‚Üí \"Agregar nuevo secreto\" ponle `HF_TOKEN` y el token que generamos ‚Üí Habilita el acceso al notebook.\n","3. Ejecutar la celda siguiente para leerlo.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DMTYDzh9rB0A","outputId":"e2489466-05ee-400f-c153-9158abd3559e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Token cargado OK\n"]}],"source":["from google.colab import userdata\n","HF_TOKEN = userdata.get('HF_TOKEN')\n","assert HF_TOKEN is not None and len(HF_TOKEN) > 0, \"Configurar el secreto 'HF_TOKEN' en Colab.\"\n","print(\"Token cargado OK\")\n"]},{"cell_type":"markdown","metadata":{"id":"VQbt6t3FrB0A"},"source":["## Parte 1 ‚Äî Uso b√°sico de LLMs con LangChain\n","\n","Trabajaremos con un modelo instruct accesible v√≠a Inference API. Para minimizar fricci√≥n, usaremos un modelo abierto.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fNzk__gZrB0B","outputId":"d7e9cd03-2f9a-4ced-dc22-c7e5f617f510"},"outputs":[{"name":"stdout","output_type":"stream","text":["Un LLM (Large Language Model) es un tipo de modelo de inteligencia artificial entrenado en grandes vol√∫menes de texto para entender, generar y realizar tareas relacionadas con el lenguaje humano.  \n","Casos de uso incluyen responder preguntas de forma natural y generar textos como art√≠culos, emails o historias.  \n","Tambi√©n se usan en asistentes virtuales, traducci√≥n autom√°tica y an√°lisis de sentimientos.\n"]}],"source":["from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","\n","MODEL_ID = \"Qwen/Qwen3-4B-Instruct-2507\"\n","\n","hf_endpoint = HuggingFaceEndpoint(\n","    repo_id=MODEL_ID,\n","    task=\"conversational\",\n","    huggingfacehub_api_token=HF_TOKEN,\n","    temperature=0.7,\n","    max_new_tokens=256,\n",")\n","\n","llm = ChatHuggingFace(llm=hf_endpoint)\n","\n","prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"Eres un asistente √∫til y conciso.\"),\n","    (\"human\", \"Responde a la siguiente instrucci√≥n: {instruccion}\"),\n","])\n","\n","chain = prompt | llm | StrOutputParser()\n","print(chain.invoke({\"instruccion\": \"Explica en 3 frases qu√© es un LLM y nombra 2 casos de uso.\"}))"]},{"cell_type":"markdown","metadata":{"id":"JM0fs9ZLrB0B"},"source":["### Ejercicio 1.1 (10 min)\n","\n","- Probar 3 variaciones de `temperature` y observar el cambio en estilo.\n","- Cambiar el rol del `system` para forzar un estilo (p.ej., ‚Äúresponde con vi√±etas y m√°ximo 3 l√≠neas‚Äù).\n","- Pregunta sugerida: ‚ÄúResume la diferencia entre entrenamiento y fine-tuning en 3 puntos.‚Äù\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mcTYMM-srB0B"},"outputs":[],"source":["from typing import List\n","\n","instruccion: str = \"Resume la diferencia entre entrenamiento y fine-tuning en 3 puntos.\"\n","temperaturas: List[float] = [0.0, 0.7, 1.2]\n","\n","def ejecutar_variacion(temperature: float) -> str:\n","    # TODO: crear endpoint conversacional con 'temperature' y devolver el texto\n","    # Debe usar: MODEL_ID, HF_TOKEN, task=\"conversational\"\n","    raise NotImplementedError\n","\n","for t in temperaturas:\n","    print(f\"\\n==== temperature: {t} ====\")\n","    print(ejecutar_variacion(t))\n","\n","def ejecutar_estilo(instruccion: str) -> str:\n","    # TODO: crear prompt de estilo (system) + LLM base conversacional y devolver el texto\n","    raise NotImplementedError\n","\n","print(\"\\n==== estilo forzado ====\")\n","print(ejecutar_estilo(instruccion))"]},{"cell_type":"markdown","metadata":{"id":"Mi_Cg8IMrB0C"},"source":["## Parte 1.2 ‚Äî Par√°metros de decodificaci√≥n\n","\n","Ajustaremos par√°metros como `top_p`, `repetition_penalty` y `max_new_tokens` para observar su efecto en la generaci√≥n.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lCnXq_QrB0C"},"outputs":[],"source":["# Exploraci√≥n de par√°metros de decodificaci√≥n\n","from typing import Dict, Any\n","from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n","from langchain_core.output_parsers import StrOutputParser\n","\n","consulta: str = \"Escribe una analog√≠a breve para explicar RAG a un p√∫blico no t√©cnico.\"\n","\n","configuraciones: Dict[str, Dict[str, Any]] = {\n","    \"baseline\":   {\"temperature\": 0.7, \"top_p\": 0.95, \"repetition_penalty\": 1.0, \"max_new_tokens\": 128},\n","    \"creativo\":   {\"temperature\": 1.1, \"top_p\": 0.90, \"repetition_penalty\": 1.0, \"max_new_tokens\": 128},\n","    \"controlado\": {\"temperature\": 0.2, \"top_p\": 0.80, \"repetition_penalty\": 1.1, \"max_new_tokens\": 96},\n","}\n","\n","for nombre, cfg in configuraciones.items():\n","    tmp_endpoint = HuggingFaceEndpoint(\n","        repo_id=MODEL_ID,\n","        task=\"conversational\",\n","        huggingfacehub_api_token=HF_TOKEN,\n","        temperature=cfg[\"temperature\"],\n","        top_p=cfg[\"top_p\"],\n","        repetition_penalty=cfg[\"repetition_penalty\"],\n","        max_new_tokens=cfg[\"max_new_tokens\"],\n","    )\n","    tmp_llm = ChatHuggingFace(llm=tmp_endpoint)\n","    salida = (prompt | tmp_llm | StrOutputParser()).invoke({\"instruccion\": consulta})\n","    print(f\"\\n==== {nombre} ({cfg}) ====\\n{salida}\")"]},{"cell_type":"markdown","metadata":{"id":"PFWQ7vryrB0C"},"source":["## Parte 2 ‚Äî Prompt engineering avanzado\n","\n","Exploraremos estrategias para mejorar la calidad y control de las respuestas: zero-shot, few-shot, restricciones de estilo, salida estructurada y Chain of Thought.\n"]},{"cell_type":"markdown","metadata":{"id":"n1U5MiS1rB0C"},"source":["### Conceptos clave: Zero-shot, Few-shot, CoT y Roles\n","\n","- Zero-shot: el modelo resuelve la tarea solo con instrucciones; no se proporcionan ejemplos.\n","- Few-shot: adem√°s de la instrucci√≥n, se incluyen 1-3 ejemplos que muestran el formato y estilo deseados.\n","- Chain-of-Thought (CoT): se gu√≠a al modelo para mostrar pasos intermedios de razonamiento (p.ej., ‚Äúrazona paso a paso‚Äù) antes de una respuesta final.\n","- Role prompting: se asigna un rol (p.ej., ‚Äúact√∫a como profesor de IA‚Äù) para influir en el estilo y nivel de detalle.\n","- JSON output: se pide una salida estricta en formato JSON y se valida con un parser.\n","\n","Lectura recomendada: gu√≠a de prompt engineering avanzada en `https://learnprompting.org/docs/introduction`.\n"]},{"cell_type":"markdown","metadata":{"id":"LiF9jJRfrB0C"},"source":["### Zero-shot y Few-shot\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fNZ9KnrLrB0D","outputId":"0d87f5fd-e84b-4da8-d926-d12e9494575f"},"outputs":[{"name":"stdout","output_type":"stream","text":["=== ZERO-SHOT ===\n","Overfitting occurs when a model learns noise instead of patterns.  \n","Overcomplicated models fail on new, unseen data.  \n","Overfitting reduces generalization in predictions.\n","\n","=== FEW-SHOT ===\n","O Viola la generalizaci√≥n al ajustarse demasiado a datos de entrenamiento  \n","V Eval√∫a mal en datos nuevos por falta de robustez  \n","E Excede el poder de representaci√≥n del modelo\n"]}],"source":["# Zero-shot vs Few-shot (diferencia marcada con patr√≥n acr√≥stico)\n","from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","\n","# LLM m√°s determinista\n","det_endpoint = HuggingFaceEndpoint(\n","    repo_id=MODEL_ID, task=\"conversational\",\n","    huggingfacehub_api_token=HF_TOKEN, temperature=0.0, max_new_tokens=128\n",")\n","llm_det = ChatHuggingFace(llm=det_endpoint)\n","parser = StrOutputParser()\n","\n","# Patr√≥n no obvio: acr√≥stico O-V-E (Overfitting), cada l√≠nea empieza con esa letra\n","instruccion = (\n","    \"Escribe EXACTAMENTE 3 l√≠neas sobre 'overfitting'. \"\n","    \"Cada l√≠nea debe comenzar con O, luego V, luego E (en ese orden). \"\n","    \"6-10 palabras por l√≠nea. Sin texto extra.\"\n",")\n","\n","zero_shot = ChatPromptTemplate.from_messages([\n","    (\"system\", \"Sigue estrictamente las instrucciones del usuario.\"),\n","    (\"human\", \"{instruccion}\")\n","])\n","\n","few_shot = ChatPromptTemplate.from_messages([\n","    (\"system\", \"Sigue estrictamente las instrucciones del usuario.\"),\n","    # Ejemplo: el patr√≥n se demuestra con otro tema y otro acr√≥stico (R-E-G)\n","    (\"human\", \"Escribe EXACTAMENTE 3 l√≠neas sobre 'regularizaci√≥n'. \"\n","              \"Cada l√≠nea debe comenzar con R, luego E, luego G. \"\n","              \"6-10 palabras por l√≠nea. Sin texto extra.\"),\n","    (\"ai\", \"R Reduce complejidad para evitar ajustes al ruido\\n\"\n","           \"E Estabiliza el aprendizaje con penalizaciones adecuadas\\n\"\n","           \"G Generaliza mejor limitando pesos excesivamente grandes\"),\n","    # Ahora se pide el caso real con el acr√≥stico O-V-E\n","    (\"human\", \"{instruccion}\")\n","])\n","\n","print(\"=== ZERO-SHOT ===\")\n","print((zero_shot | llm_det | parser).invoke({\"instruccion\": instruccion}))\n","\n","print(\"\\n=== FEW-SHOT ===\")\n","print((few_shot | llm_det | parser).invoke({\"instruccion\": instruccion}))"]},{"cell_type":"markdown","metadata":{"id":"4b7hTF4wrB0D"},"source":["### Role prompting"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_VhEgQZrB0D","outputId":"fd5e846d-cafc-4dff-fb4f-f762db9e9cd5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Claro, aqu√≠ tienes una explicaci√≥n breve y clara:\n","\n","**Qu√© es el aprendizaje por refuerzo (Reinforcement Learning):**  \n","Es un tipo de inteligencia artificial donde un agente (como un robot o un programa) aprende a tomar decisiones para maximizar una recompensa a lo largo del tiempo. No tiene acceso a datos etiquetados, sino que aprende probando diferentes acciones y vi√©ndose recompensado o sancionado seg√∫n los resultados.\n","\n","üîç **Por ejemplo:**  \n","Imagina que un agente quiere aprender a jugar al ajedrez. Cada vez que gana, recibe una recompensa. Si pierde, la recompensa es baja o negativa. Con el tiempo, el agente aprende qu√© movimientos le llevan a ganar m√°s.\n","\n","### 2 ejemplos de aplicaci√≥n:\n","1. **Juegos de video** (como AlphaGo o Deep Q-Networks): Los algoritmos aprenden a jugar mejor jugando miles de partidas y recibiendo recompensas por ganar.\n","2. **Rob√≥tica y automatizaci√≥n** (como un robot que aprende a caminar o navegar): El robot recibe recompensas cuando se mueve bien o evita ca√≠das, y ajusta su comportamiento para mejorar.\n","\n","En resumen: **El aprendizaje por refuerzo es aprender por intentos, errores y recompensas.**\n"]}],"source":["# Role prompting\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","\n","role_prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"Act√∫a como profesor de IA de nivel intermedio. S√© claro, estructurado y usa ejemplos sencillos.\"),\n","    (\"human\", \"Explica brevemente qu√© es el aprendizaje por refuerzo y menciona 2 ejemplos de aplicaci√≥n.\"),\n","])\n","\n","print((role_prompt | llm | StrOutputParser()).invoke({}))\n"]},{"cell_type":"markdown","metadata":{"id":"BFhoZDI4rB0D"},"source":["### CoT (Chain-of-Thought) prompting"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9AK2aANwrB0D","outputId":"2e40d0fd-99ee-4a28-943a-63dc34811eeb"},"outputs":[{"name":"stdout","output_type":"stream","text":["=== SIN CoT ===\n","9.09%\n","\n","=== CON CoT ===\n","Vamos a resolver este problema paso a paso usando el **teorema de Bayes**.\n","\n","---\n","\n","### Datos del problema:\n","\n","- Probabilidad de tener la enfermedad (prevalencia):  \n","  \\( P(E) = 1\\% = 0.01 \\)\n","\n","- Probabilidad de no tener la enfermedad:  \n","  \\( P(\\neg E) = 1 - 0.01 = 0.99 \\)\n","\n","- Sensibilidad de la prueba (probabilidad de dar positivo si tienes la enfermedad):  \n","  \\( P(T^+ | E) = 90\\% = 0.90 \\)\n","\n","- Especificidad de la prueba (probabilidad de dar negativo si no tienes la enfermedad):  \n","  \\( P(T^- | \\neg E) = 90\\% = 0.90 \\)\n","\n","Esto implica que:\n","\n","- El error de falsa positiva es \\( P(T^+ | \\neg E) = 1 - 0.90 = 0.10 \\)\n","\n","Nos piden:  \n","**Probabilidad de que una persona realmente tenga la enfermedad dado que dio positivo.**  \n","Es decir:  \n","\\( P(E | T^+) = ? \\)\n","\n","---\n","\n","### Usamos el teorema de Bayes:\n","\n","\\[\n","P(E | T^+) = \\frac{P(T^+ | E) \\cdot P(E)}{P(T^+)}\n","\\]\n","\n","Donde \\( P(T^+) \\) es la probabilidad total de dar positivo. Para calcularlo, usamos el **teorema de la probabilidad total**:\n","\n","\\[\n","P(T^+) = P(T^+ | E) \\cdot P(E) + P(T^+ | \\neg E) \\cdot P(\\neg E)\n","\\]\n","\n","Sustituimos los valores:\n","\n","\\[\n","P(T^+) = (0.90)(0.01) + (0.10)(0.99) = 0.009 + 0.099 = 0.108\n","\\]\n","\n","Ahora aplicamos Bayes:\n","\n","\\[\n","P(E | T^+) = \\frac{0.90 \\times 0.01}{0.108} = \\frac{0.009}{0.108} \\approx 0.0833\n","\\]\n","\n","Convertimos a porcentaje:\n","\n","\\[\n","0.0833 \\times 100 \\approx 8.33\\%\n","\\]\n","\n","---\n","\n","Respuesta final: 8.33%\n"]}],"source":["# Prompts SIN CoT y CON CoT (Bayes) ‚Äî nscale-compatible\n","\n","from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","\n","problema = (\n","    \"En una poblaci√≥n, 1% tiene la enfermedad. La prueba tiene 90% de sensibilidad y 90% de especificidad. \"\n","    \"Si una persona da positivo, ¬øcu√°l es la probabilidad (en %) de que realmente est√© enferma?\"\n",")\n","\n","parser = StrOutputParser()\n","\n","# SIN CoT: SOLO porcentaje en una l√≠nea (recorta tokens)\n","endpoint_sin = HuggingFaceEndpoint(\n","    repo_id=MODEL_ID, task=\"conversational\",\n","    huggingfacehub_api_token=HF_TOKEN, temperature=0.0, max_new_tokens=6\n",")\n","llm_sin = ChatHuggingFace(llm=endpoint_sin)\n","\n","prompt_sin_cot = ChatPromptTemplate.from_messages([\n","    (\"system\", \"Devuelve SOLO un n√∫mero en formato porcentaje (ej: 8.33%). \"\n","               \"Sin explicaciones, sin ecuaciones, sin texto extra.\"),\n","    (\"human\", \"{q}\")\n","])\n","\n","# CON CoT: piensa paso a paso y cierra con una l√≠nea final\n","endpoint_con = HuggingFaceEndpoint(\n","    repo_id=MODEL_ID, task=\"conversational\",\n","    huggingfacehub_api_token=HF_TOKEN, temperature=0.0, max_new_tokens=256\n",")\n","llm_con = ChatHuggingFace(llm=endpoint_con)\n","\n","prompt_con_cot = ChatPromptTemplate.from_messages([\n","    (\"system\", \"T√≥mate tu tiempo y piensa paso a paso usando Bayes. \"\n","               \"Al final, da una sola l√≠nea con: 'Respuesta final: <n>%'\"),\n","    (\"human\", \"{q}\")\n","])\n","\n","print(\"=== SIN CoT ===\")\n","print((prompt_sin_cot | llm_sin | parser).invoke({\"q\": problema}))\n","\n","print(\"\\n=== CON CoT ===\")\n","print((prompt_con_cot | llm_con | parser).invoke({\"q\": problema}))"]},{"cell_type":"markdown","metadata":{"id":"6SPYi9X1rB0F"},"source":["### Salida estructurada (JSON Output Parser)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCegKKRDrB0F","outputId":"0a6642d1-926b-4683-8e6a-0da447fc7e05"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"titulo\": \"RAG (Retrieval-Augmented Generation)\",\n","  \"puntos_clave\": [\n","    \"RAG combina la recuperaci√≥n de informaci√≥n de una base de conocimientos con la generaci√≥n de texto para mejorar la precisi√≥n y relevancia.\",\n","    \"Permite que los modelos de lenguaje utilicen informaci√≥n de documentos externos en tiempo real durante la generaci√≥n de respuestas.\",\n","    \"Reduce el riesgo de generar contenido fabricado al basarse en fuentes verificadas de informaci√≥n.\"\n","  ],\n","  \"dificultad\": \"intermedio\"\n","}\n","JSON v√°lido con las claves requeridas.\n"]}],"source":["# Salida estructurada (JSON) con output parser\n","import json\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","\n","json_prompt = ChatPromptTemplate.from_template(\n","    \"\"\"\n","    Eres un asistente que devuelve SIEMPRE JSON v√°lido. Dado un tema, devuelve un objeto con:\n","    - \"titulo\": string\n","    - \"puntos_clave\": lista de 3 strings\n","    - \"dificultad\": uno de [\"b√°sico\", \"intermedio\", \"avanzado\"]\n","    Responde SOLO con JSON v√°lido sin texto adicional.\n","    Tema: {tema}\n","    \"\"\"\n",")\n","\n","json_text = (json_prompt | llm | StrOutputParser()).invoke({\"tema\": \"RAG\"})\n","print(json_text)\n","\n","data = json.loads(json_text)\n","assert set([\"titulo\", \"puntos_clave\", \"dificultad\"]).issubset(data.keys())\n","print(\"JSON v√°lido con las claves requeridas.\")\n"]},{"cell_type":"markdown","metadata":{"id":"CC4DngMVrB0G"},"source":["## Ejercicios ‚Äî Parte 2\n","\n","Resuelve los siguientes ejercicios. Modifica prompts y par√°metros si es necesario y justifica brevemente tus decisiones (en una celda de texto).\n"]},{"cell_type":"markdown","metadata":{"id":"OFAmf9D0rB0G"},"source":["### Ejercicio 2.1 ‚Äî Zero-shot vs Few-shot\n","\n","- Tarea: explicar ‚Äúregularizaci√≥n L2‚Äù en 3 vi√±etas claras para un p√∫blico t√©cnico.\n","- Paso 1 (zero-shot): crea un prompt sin ejemplos y observa el resultado.\n","- Paso 2 (few-shot): agrega 1-2 ejemplos de estilo y compara la salida.\n","- Pregunta gu√≠a: ¬ømejor√≥ la precisi√≥n o claridad con pocos ejemplos? Justifica.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fd2vCaKlrB0G"},"outputs":[],"source":["def zero_shot_l2() -> str:\n","    # TODO: construir prompt zero-shot (3 vi√±etas) y llamar al LLM\n","    raise NotImplementedError\n","\n","def few_shot_l2() -> str:\n","    # TODO: construir prompt con 1-2 ejemplos y llamar al LLM\n","    raise NotImplementedError\n","\n","print(\"\\n=== ZERO-SHOT ===\\n\")\n","print(zero_shot_l2())\n","\n","print(\"\\n=== FEW-SHOT ===\\n\")\n","print(few_shot_l2())"]},{"cell_type":"markdown","metadata":{"id":"gsrH2ZdtrB0G"},"source":["### Ejercicio 2.2 ‚Äî Chain-of-Thought (CoT)\n","\n","- Tarea: dado un problema de evaluaci√≥n de modelos, razonar paso a paso y entregar una conclusi√≥n final breve.\n","- Problema sugerido: ‚Äú¬øPor qu√© accuracy puede ser enga√±oso en un dataset muy desbalanceado y qu√© m√©trica alternativa usar√≠as?‚Äù\n","- Pista: pide expl√≠citamente ‚Äúrazona paso a paso y luego da una respuesta final breve en una l√≠nea‚Äù.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37-CDC6irB0G"},"outputs":[],"source":["def cot_razonamiento(problema: str) -> str:\n","    # TODO: pedir \"razona paso a paso\" y cerrar con una l√≠nea final\n","    raise NotImplementedError\n","\n","problema: str = \"¬øPor qu√© accuracy puede ser enga√±oso en un dataset muy desbalanceado y qu√© m√©trica alternativa usar√≠as?\"\n","print(cot_razonamiento(problema))"]},{"cell_type":"markdown","metadata":{"id":"cRDMh9ewrB0G"},"source":["### Ejercicio 2.3 ‚Äî Role prompting\n","\n","- Tarea: explicar el ‚Äúsesgo de selecci√≥n‚Äù a un equipo de data engineering con ejemplos concisos.\n","- Rol: ‚ÄúAct√∫a como l√≠der t√©cnico de datos; s√© pragm√°tico y directo, con vi√±etas concretas‚Äù.\n","- Objetivo: evaluar c√≥mo cambia el estilo bajo un rol t√©cnico espec√≠fico.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LnGf_iFWrB0G"},"outputs":[],"source":["def explicar_sesgo_seleccion() -> str:\n","    # TODO: role \"l√≠der t√©cnico de datos\", 3 vi√±etas + 1 ejemplo pr√°ctico\n","    raise NotImplementedError\n","\n","print(explicar_sesgo_seleccion())"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}